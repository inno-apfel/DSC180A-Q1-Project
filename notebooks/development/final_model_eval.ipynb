{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a42858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7c792",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331917fa",
   "metadata": {},
   "source": [
    "For our modeling approaches, certain models would require lagged data while other, time-series oriented models, would be able to use unlagged data.\n",
    "\n",
    "As such we will load in two variants of our data:\n",
    "- one unlagged dataset\n",
    "- one where all features except 'est' and 'year' are lagged by 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../src/data/temp/zbp_totals_with_features.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2dbbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../src/data/temp/lagged_zbp_totals_with_features.csv'\n",
    "lagged_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e833d66",
   "metadata": {},
   "source": [
    "# Drop Categorical Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=data.select_dtypes(exclude=['int64', 'float64']).columns)\n",
    "lagged_data = lagged_data.drop(columns=lagged_data.select_dtypes(exclude=['int64', 'float64']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316896d1",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256afe8e",
   "metadata": {},
   "source": [
    "Given our testing regimine, we will need two variants of each dataset\n",
    "- Short-Term: Training [2012-2020], Testing [2021]\n",
    "- Long-Term: Training [2012-2018], Testing [2019-2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51552fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_year(data, end_year):\n",
    "    data_train = data[data['year'] <= end_year]\n",
    "    data_test = data[data['year'] > end_year]\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f10a9",
   "metadata": {},
   "source": [
    "### Short-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2ce02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_year = 2020\n",
    "\n",
    "short_data_train, short_data_test = train_test_split_by_year(data, end_year)\n",
    "short_lagged_data_train, short_lagged_data_test = train_test_split_by_year(lagged_data, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168dcbe",
   "metadata": {},
   "source": [
    "### Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e05517",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_year = 2018\n",
    "\n",
    "long_data_train, long_data_test = train_test_split_by_year(data, end_year)\n",
    "long_lagged_data_train, long_lagged_data_test = train_test_split_by_year(lagged_data, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a99ab3e",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data_train, data_test):\n",
    "    train_mean = data_train.mean()\n",
    "    train_mean['zip'] = 0\n",
    "    train_std = data_train.std()\n",
    "    train_std['zip'] = 1\n",
    "    \n",
    "    data_train_standardized = (data_train - train_mean) / train_std\n",
    "    data_test_standardized = (data_test - train_mean) / train_std\n",
    "    \n",
    "    return data_train_standardized, data_test_standardized, (train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff45420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstandardize_series(ser, mean, std):\n",
    "    return (ser*std)+mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9607893",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_std_data_train, short_std_data_test, short_train_stats = standardize_data(short_data_train, short_data_test)\n",
    "short_train_mean, short_train_std = short_train_stats\n",
    "\n",
    "long_std_data_train, long_std_data_test, long_train_stats = standardize_data(long_data_train, long_data_test)\n",
    "long_train_mean, long_train_std = long_train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1467b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_lagged_std_data_train, short_lagged_std_data_test, short_lagged_train_stats = standardize_data(short_lagged_data_train, short_lagged_data_test)\n",
    "short_lagged_train_mean, short_lagged_train_std = short_lagged_train_stats\n",
    "\n",
    "long_lagged_std_data_train, long_lagged_std_data_test, long_lagged_train_stats = standardize_data(long_lagged_data_train, long_lagged_data_test)\n",
    "long_lagged_train_mean, long_lagged_train_std = long_lagged_train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4e06a",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dba99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ohe(data_train, data_test):\n",
    "    \n",
    "    preproc = ColumnTransformer([('onehots', OneHotEncoder(handle_unknown='ignore'), ['zip'])]\n",
    "                             ,remainder = 'passthrough')\n",
    "    data_ohe_train = preproc.fit_transform(data_train)\n",
    "    \n",
    "    feature_names = preproc.get_feature_names_out()\n",
    "    feature_names = np.char.replace(feature_names.astype('str'), 'onehots__','')\n",
    "    feature_names = np.char.replace(feature_names, 'remainder__','')\n",
    "    \n",
    "    data_ohe_train = pd.DataFrame(data_ohe_train, columns=feature_names)\n",
    "    \n",
    "    data_ohe_test = preproc.transform(data_test)\n",
    "    data_ohe_test = pd.DataFrame(data_ohe_test, columns=feature_names)\n",
    "    \n",
    "    return data_ohe_train, data_ohe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_ohe_data_train, short_ohe_data_test = convert_to_ohe(short_std_data_train, short_std_data_test)\n",
    "long_ohe_data_train, long_ohe_data_test = convert_to_ohe(long_std_data_train, long_std_data_test)\n",
    "\n",
    "short_lagged_ohe_data_train, short_lagged_ohe_data_test = convert_to_ohe(short_lagged_std_data_train, short_lagged_std_data_test)\n",
    "long_lagged_ohe_data_train, long_lagged_ohe_data_test = convert_to_ohe(long_lagged_std_data_train, long_lagged_std_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0a2844",
   "metadata": {},
   "source": [
    "### DL Test Set Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cea082",
   "metadata": {},
   "source": [
    "our tensorflow models require at least 1 previous timestamp to make predictions. To replicate testing procedure of our sklearn models add last timestep of training into test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_short_data_year = short_ohe_data_train['year'].unique().max()\n",
    "tf_short_ohe_data_train = short_ohe_data_train[short_ohe_data_train['year']<last_short_data_year]\n",
    "tf_short_ohe_data_test = pd.concat([short_ohe_data_train[short_ohe_data_train['year']==last_short_data_year], short_ohe_data_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffbc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_long_data_year = long_ohe_data_train['year'].unique().max()\n",
    "tf_long_ohe_data_train = long_ohe_data_train[long_ohe_data_train['year']<last_long_data_year]\n",
    "tf_long_ohe_data_test = pd.concat([long_ohe_data_train[long_ohe_data_train['year']==last_long_data_year], long_ohe_data_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc940d53",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65857bd",
   "metadata": {},
   "source": [
    "### Corr Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66191d10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_k = 30\n",
    "corr = short_lagged_ohe_data_train.corr()[['est']].sort_values(by='est', ascending=False)\n",
    "vmin = corr.min()\n",
    "vmax = corr.max()\n",
    "corr_thresh = corr.abs().sort_values('est', ascending=False).iloc[top_k+2]['est']\n",
    "corr = corr[corr['est'].abs() > corr_thresh]\n",
    "# print(f'top {corr.shape[0]} features:')\n",
    "corr_features = corr[1:-1]\n",
    "display(corr[2:].style.background_gradient(cmap='coolwarm', vmin=vmin, vmax=vmax))\n",
    "f'top {corr[2:].shape[0]} features by pearson correlation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6ed78",
   "metadata": {},
   "source": [
    "### Forward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = short_lagged_ohe_data_train.drop(columns=['est'])\n",
    "y_train = short_lagged_ohe_data_train['est']\n",
    "X_test = short_lagged_ohe_data_test.drop(columns=['est'])\n",
    "y_test = short_lagged_ohe_data_test['est']\n",
    "\n",
    "ffs = SequentialFeatureSelector(LinearRegression(n_jobs=-1), k_features=top_k, forward=True, n_jobs=-1)\n",
    "ffs.fit(X_train, y_train)\n",
    "ffs_features = list(ffs.k_feature_names_)\n",
    "ffs_features = ffs_features[::-1]\n",
    "ffs_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4227a3",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efefec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_eval(model, data_train, data_test, included_feats, train_mean, train_std):\n",
    "    \n",
    "    if included_feats == 'all':\n",
    "        included_feats = data_train.columns.drop(['est'])\n",
    "    \n",
    "    X_train = data_train[included_feats]\n",
    "    y_train = data_train['est']\n",
    "    X_test = data_test[included_feats]\n",
    "    y_test = data_test['est']\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_preds = model.predict(X_train)\n",
    "    inverted_y_train = unstandardize_series(y_train, train_mean['est'], train_std['est'])\n",
    "    inverted_y_preds = unstandardize_series(y_preds, train_mean['est'], train_std['est'])\n",
    "    train_rmse = mean_squared_error(inverted_y_train, inverted_y_preds, squared=False)\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    inverted_y_test = unstandardize_series(y_test, train_mean['est'], train_std['est'])\n",
    "    inverted_y_preds = unstandardize_series(y_preds, train_mean['est'], train_std['est'])\n",
    "    test_rmse = mean_squared_error(inverted_y_test, inverted_y_preds, squared=False)\n",
    "    \n",
    "    return model, train_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525c73e",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a27a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(data_train, data_test, included_feats, model, param_grid):\n",
    "    \n",
    "    if included_feats == 'all':\n",
    "        included_feats = data_train.columns.drop(['est'])\n",
    "\n",
    "    X_train = data_train[included_feats]\n",
    "    y_train = data_train['est']\n",
    "    X_test = data_test[included_feats]\n",
    "    y_test = data_test['est']\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid, scoring = 'neg_root_mean_squared_error', n_jobs = -1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641cd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50], \n",
    "              'max_depth': [50]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=SEED, n_jobs=-1)\n",
    "\n",
    "gs_results = run_grid_search(short_lagged_ohe_data_train, short_lagged_ohe_data_test, 'all', rf, param_grid)\n",
    "display(gs_results.best_params_)\n",
    "\n",
    "short_rf = RandomForestRegressor(**gs_results.best_params_, random_state=SEED)\n",
    "short_rf, short_rf_train_rmse, short_rf_test_rmse = fit_eval(short_rf, short_lagged_ohe_data_train, short_lagged_ohe_data_test, \n",
    "                                                             'all', \n",
    "                                                             short_lagged_train_mean, short_lagged_train_std)\n",
    "print('train_rmse: ', short_rf_train_rmse)\n",
    "print('test_rmse: ', short_rf_test_rmse)\n",
    "\n",
    "with open('../../out/models/short_rf.pkl','wb') as f:\n",
    "    pickle.dump(short_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=SEED, n_jobs=-1)\n",
    "\n",
    "gs_results = run_grid_search(long_lagged_ohe_data_train, long_lagged_ohe_data_test, 'all', rf, param_grid)\n",
    "display(gs_results.best_params_)\n",
    "\n",
    "long_rf = RandomForestRegressor(**gs_results.best_params_, random_state=SEED)\n",
    "long_rf, long_rf_train_rmse, long_rf_test_rmse = fit_eval(long_rf, long_lagged_ohe_data_train, long_lagged_ohe_data_test, \n",
    "                                                          'all', \n",
    "                                                          long_lagged_train_mean, long_lagged_train_std)\n",
    "print('train_rmse: ', long_rf_train_rmse)\n",
    "print('test_rmse: ', long_rf_test_rmse)\n",
    "\n",
    "with open('../../out/models/long_rf.pkl','wb') as f:\n",
    "    pickle.dump(short_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d5266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = short_lagged_ohe_data_train.columns.drop(['est'])\n",
    "\n",
    "importances = long_rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in long_rf.estimators_], axis=0)\n",
    "\n",
    "top_features = pd.Series(importances, index=feature_names).sort_values(ascending=False)[:top_k].sort_values(ascending=True)\n",
    "forest_importances = top_features[:-1]\n",
    "display(forest_importances.index.to_numpy())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot(kind='barh', ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_xlabel(\"Mean decrease in impurity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdi_top_features = top_features.index[::-1]\n",
    "mdi_top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a97ae",
   "metadata": {},
   "source": [
    "### Lin Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        selected_features = [col for col in X.columns if any(name in col for name in self.feature_names)]\n",
    "        return X[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724ffc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = long_lagged_ohe_data_train.columns.drop(['est'])\n",
    "preproc = ColumnTransformer([('feature_selector', FeatureSelector(feature_names=[]), all_feats)]\n",
    "                             ,remainder = 'drop')\n",
    "pl = Pipeline(steps=[('preproc', preproc), ('reg', LinearRegression(n_jobs=-1))])\n",
    "param_grid = {'preproc__feature_selector__feature_names': [corr_features, ffs_features, mdi_top_features, all_feats]}\n",
    "\n",
    "gs_results = run_grid_search(short_lagged_ohe_data_train, short_lagged_ohe_data_test, 'all', pl, param_grid)\n",
    "\n",
    "short_lr = gs_results.best_estimator_\n",
    "short_lr, short_lr_train_rmse, short_lr_test_rmse = fit_eval(short_lr, short_lagged_ohe_data_train, short_lagged_ohe_data_test, \n",
    "                                                             'all', \n",
    "                                                             short_lagged_train_mean, short_lagged_train_std)\n",
    "print('train_rmse: ', short_lr_train_rmse)\n",
    "print('test_rmse: ', short_lr_test_rmse)\n",
    "\n",
    "with open('../../out/models/short_lr.pkl','wb') as f:\n",
    "    pickle.dump(short_lr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f45636",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer([('feature_selector', FeatureSelector(feature_names=[]), all_feats)]\n",
    "                             ,remainder = 'drop')\n",
    "pl = Pipeline(steps=[('preproc', preproc), ('reg', LinearRegression(n_jobs=-1))])\n",
    "\n",
    "gs_results = run_grid_search(short_lagged_ohe_data_train, short_lagged_ohe_data_test, 'all', pl, param_grid)\n",
    "\n",
    "long_lr = gs_results.best_estimator_\n",
    "long_lr, long_lr_train_rmse, long_lr_test_rmse = fit_eval(short_lr, long_lagged_ohe_data_train, long_lagged_ohe_data_test, \n",
    "                                                          'all', \n",
    "                                                          long_lagged_train_mean, long_lagged_train_std)\n",
    "print('train_rmse: ', long_lr_train_rmse)\n",
    "print('test_rmse: ', long_lr_test_rmse)\n",
    "\n",
    "with open('../../out/models/long_lr.pkl','wb') as f:\n",
    "    pickle.dump(long_lr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b146c20",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_lasso = LassoCV(random_state=SEED)\n",
    "short_lasso, short_lasso_train_rmse, short_lasso_test_rmse = fit_eval(short_lasso, short_lagged_ohe_data_train, short_lagged_ohe_data_test, \n",
    "                                                                      'all', \n",
    "                                                                      short_lagged_train_mean, short_lagged_train_std)\n",
    "print('train_rmse: ', short_lasso_train_rmse)\n",
    "print('test_rmse: ', short_lasso_test_rmse)\n",
    "\n",
    "with open('../../out/models/short_lasso.pkl','wb') as f:\n",
    "    pickle.dump(short_lasso, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a28bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_lasso = LassoCV(random_state=SEED)\n",
    "long_lasso, long_lasso_train_rmse, long_lasso_test_rmse = fit_eval(long_lasso, long_lagged_ohe_data_train, long_lagged_ohe_data_test, \n",
    "                                                                   'all', \n",
    "                                                                   long_lagged_train_mean, long_lagged_train_std)\n",
    "print('train_rmse: ', long_lasso_train_rmse)\n",
    "print('test_rmse: ', long_lasso_test_rmse)\n",
    "\n",
    "with open('../../out/models/long_lasso.pkl','wb') as f:\n",
    "    pickle.dump(long_lasso, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8269814f",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32976b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "class ARIMAForecast():\n",
    "    \n",
    "    def __init__(self, data, n_lag_terms ,diff_order ,window_size):\n",
    "        self.data = data\n",
    "        self.models = {}\n",
    "        self.n_lag_terms = n_lag_terms\n",
    "        self.diff_order = diff_order\n",
    "        self.window_size = window_size\n",
    "        \n",
    "    def train(self):\n",
    "        for zip_code in self.data['zip'].unique():\n",
    "            # filter\n",
    "            curr_data = self.data[self.data['zip']==zip_code][['year', 'est']].set_index('year')\n",
    "            start_time = curr_data.index[0]\n",
    "            # train\n",
    "            model = ARIMA(curr_data, order=(self.n_lag_terms ,self.diff_order ,self.window_size))\n",
    "            try:\n",
    "                results = model.fit()\n",
    "                self.models[zip_code] = (results, start_time)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    def forecast(self, year):\n",
    "        preds = []\n",
    "        # last year seen in the training set\n",
    "        # used to calculate start range for forecast, to avoid predicting values in training set\n",
    "        data_last_year = self.data['year'].max()\n",
    "        for zip_code, model_info in self.models.items():\n",
    "            model, start_time = model_info\n",
    "            # make predictions\n",
    "            curr_pred = model.predict(data_last_year-start_time+1,year-start_time)\n",
    "            # modify results into a df object\n",
    "            curr_pred = curr_pred.to_frame().assign(zip=np.full(curr_pred.shape[0], zip_code)).reset_index()\n",
    "            curr_pred = curr_pred.rename(columns={'index':'year', 0:'est', 'predicted_mean':'est'})\n",
    "            # address issue where timestamp of some predictions is the number of years after the last year\n",
    "            # in the training data rather than a timestamp object\n",
    "            max_int = curr_pred[curr_pred['year'].apply(lambda x: type(x) == int)]['year'].max()\n",
    "            curr_pred['year'] = curr_pred['year'].apply(lambda x: year-max_int+x if (type(x) == int) else x)\n",
    "            preds += [curr_pred]\n",
    "            \n",
    "        return pd.concat(preds, ignore_index=True).reset_index(drop=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ae8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ARIMAForecast(short_data_train, 1, 1, 1)\n",
    "\n",
    "model.train()\n",
    "\n",
    "forecast = model.forecast(short_data_test['year'].max())\n",
    "preds_labels = forecast.merge(short_data_test, on=['zip', 'year'], suffixes=('_pred', '_true'))\n",
    "\n",
    "short_arima_train_rmse = None\n",
    "short_arima_test_rmse = mean_squared_error(preds_labels['est_true'], preds_labels['est_pred'], squared=False)\n",
    "\n",
    "with open('../../out/models/short_arima.pkl','wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2085d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMAForecast(long_data_train, 1, 1, 1)\n",
    "\n",
    "model.train()\n",
    "\n",
    "forecast = model.forecast(long_data_test['year'].max())\n",
    "preds_labels = forecast.merge(long_data_test, on=['zip', 'year'], suffixes=('_pred', '_true'))\n",
    "\n",
    "long_arima_train_rmse = None\n",
    "long_arima_test_rmse = mean_squared_error(preds_labels['est_true'], preds_labels['est_pred'], squared=False)\n",
    "\n",
    "with open('../../out/models/long_arima.pkl','wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b660e0d",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a57d4",
   "metadata": {},
   "source": [
    "#### Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceac9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    \n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                train_df=long_ohe_data_train, test_df=long_ohe_data_test,\n",
    "                label_columns=None, batch_size=1):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                          enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in\n",
    "                               enumerate(train_df.columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "    def split_window(self, features):\n",
    "    \n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "\n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "    \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=False,\n",
    "            batch_size=self.batch_size,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "    \n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def example(self):\n",
    "        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "        result = getattr(self, '_example', None)\n",
    "        if result is None:\n",
    "            # No example batch was found, so get one from the `.train` dataset\n",
    "            result = next(iter(self.train))\n",
    "            # And cache it for next time\n",
    "            self._example = result\n",
    "        return result\n",
    "    \n",
    "    def plot(self, model=None, plot_col='est', max_subplots=3):\n",
    "        inputs, labels = self.example\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(max_n, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                            marker='X', edgecolors='k', label='Predictions',\n",
    "                            c='#ff7f0e', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "                plt.legend()\n",
    "\n",
    "        plt.xlabel('year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f96b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IN_STEPS = 1\n",
    "OUT_STEPS = 1\n",
    "\n",
    "single_step_window = WindowGenerator(input_width=IN_STEPS,\n",
    "                                    label_width=OUT_STEPS,\n",
    "                                    shift=OUT_STEPS,\n",
    "                                    label_columns=['est'],\n",
    "                                    batch_size=1)\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b342ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_window = WindowGenerator(input_width=5,\n",
    "                              label_width=5,\n",
    "                              shift=1,\n",
    "                              label_columns=['est'],\n",
    "                              batch_size=1)\n",
    "wide_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f56473",
   "metadata": {},
   "source": [
    "#### Splitting Data into ZIP Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ed59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_zip_code(data_train, data_test, window, ignore_test=False):\n",
    "    \n",
    "    data_train_by_zc_tf = {}\n",
    "    for zip_code in data_train.filter(like='zip').columns:\n",
    "        data_by_zc = data_train[data_train[zip_code]==1]\n",
    "        data_train_by_zc_tf[zip_code] = window.make_dataset(data_by_zc)\n",
    "        \n",
    "    \n",
    "    data_test_by_zc_tf = {}\n",
    "    \n",
    "    if not ignore_test:\n",
    "        for zip_code in data_test.filter(like='zip').columns:\n",
    "            data_by_zc = data_test[data_test[zip_code]==1]\n",
    "            data_test_by_zc_tf[zip_code] = window.make_dataset(data_by_zc)\n",
    "        \n",
    "    return data_train_by_zc_tf, data_test_by_zc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_data_train_by_zc_tf, short_data_test_by_zc_tf = split_by_zip_code(short_ohe_data_train, short_ohe_data_test, single_step_window, ignore_test=True)\n",
    "long_data_train_by_zc_tf, long_data_test_by_zc_tf = split_by_zip_code(long_ohe_data_train, long_ohe_data_test, single_step_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16222b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_short_data_train_by_zc_tf, wide_short_data_test_by_zc_tf = split_by_zip_code(short_ohe_data_train, short_ohe_data_test, wide_window, ignore_test=True)\n",
    "wide_long_data_train_by_zc_tf, wide_long_data_test_by_zc_tf = split_by_zip_code(long_ohe_data_train, long_ohe_data_test, wide_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c21a4",
   "metadata": {},
   "source": [
    "# TF MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a808f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_all_zip(model, data_train_by_zc):\n",
    "    total = 0\n",
    "    i = 0\n",
    "    for zc in data_train_by_zc.keys():\n",
    "        total += unstandardize_series(model.evaluate(data_train_by_zc[zc], verbose=0)[0], \n",
    "                                      long_train_mean['est'], long_train_std['est'])\n",
    "        i += 1\n",
    "    return np.sqrt(total/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc67748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_plot_model(model, wide_data, window):\n",
    "    inputs, labels = next(iter(wide_data['zip_91915.0']))\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_col_index = window.column_indices['est']\n",
    "\n",
    "    plt.ylabel(f'est [normed]')\n",
    "    plt.plot(window.input_indices, inputs[0, :, plot_col_index],\n",
    "             label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "    if window.label_columns:\n",
    "        label_col_index = window.label_columns_indices.get('est', None)\n",
    "    else:\n",
    "        label_col_index = plot_col_index\n",
    "\n",
    "    plt.scatter(window.label_indices, labels[0, :, label_col_index],\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "\n",
    "    predictions = model(inputs)\n",
    "    print(predictions[0, :, label_col_index])\n",
    "    plt.scatter(window.label_indices, predictions[0, :, label_col_index],\n",
    "                marker='X', edgecolors='k', label='Predictions',\n",
    "                c='#ff7f0e', s=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25730e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model, data_train_by_zc, data_test_by_zc, num_epochs):\n",
    "    \n",
    "    KERAS_VERBOSITY = 0\n",
    "    patience = 4\n",
    "\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=[tf.keras.losses.MeanSquaredError()])\n",
    "    \n",
    "    for epoch in tqdm(np.arange(num_epochs)):\n",
    "        \n",
    "        if (len(losses) >= 2) and (np.abs(losses[-1] - losses[-2]) < 0.1):\n",
    "            patience -= 1\n",
    "        if patience <= 0:\n",
    "            break\n",
    "        \n",
    "        loss_curr_epoch = 0\n",
    "        val_loss_curr_epoch = 0\n",
    "        i = 0\n",
    "        \n",
    "        data_train_by_zip = list(data_train_by_zc.values())\n",
    "        data_test_by_zip = list(data_test_by_zc.values())\n",
    "        \n",
    "        for i in np.arange(len(data_train_by_zip)):\n",
    "            \n",
    "            history = model.fit(data_train_by_zip[i], epochs=1, validation_data=data_train_by_zip[i], verbose=KERAS_VERBOSITY)\n",
    "            loss_curr_epoch += history.history['loss'][0]\n",
    "            val_loss_curr_epoch += history.history['val_loss'][0]\n",
    "            i += 1\n",
    "                \n",
    "        losses += [np.sqrt(unstandardize_series(loss_curr_epoch/i, long_train_mean['est'], long_train_std['est']))]\n",
    "        val_losses += [np.sqrt(unstandardize_series(val_loss_curr_epoch/i, long_train_mean['est'], long_train_std['est']))]\n",
    "                \n",
    "    return losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ed37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f41ce",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self, label_index=None):\n",
    "        super().__init__()\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.label_index is None:\n",
    "            return inputs\n",
    "        result = inputs[:, :, self.label_index]\n",
    "        return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4aa9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_indices = {name: i for i, name in enumerate(long_ohe_data_train.columns)}\n",
    "baseline = Baseline(label_index=column_indices['est'])\n",
    "baseline.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 metrics=[tf.keras.losses.MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc3fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', baseline(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_plot_model(baseline, wide_long_data_train_by_zc_tf, wide_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9713c3c",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ef3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_linear = tf.keras.Sequential([tf.keras.layers.Dense(units=1)])\n",
    "long_linear = tf.keras.Sequential([tf.keras.layers.Dense(units=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60780af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', single_step_window.example[0].shape)\n",
    "print('Output shape:', long_linear(single_step_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02672860",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses = compile_and_fit(short_linear, short_data_train_by_zc_tf, short_data_test_by_zc_tf, MAX_EPOCHS)\n",
    "plt.plot(np.arange(1, len(losses) + 1), losses, label='train')\n",
    "plt.plot(np.arange(1, len(val_losses) + 1), val_losses, label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses = compile_and_fit(long_linear, long_data_train_by_zc_tf, long_data_test_by_zc_tf, MAX_EPOCHS)\n",
    "plt.plot(np.arange(1, len(losses) + 1), losses, label='train')\n",
    "plt.plot(np.arange(1, len(val_losses) + 1), val_losses, label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', long_linear(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d84f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_plot_model(long_linear, wide_long_data_train_by_zc_tf, wide_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8700179",
   "metadata": {},
   "source": [
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_dense = tf.keras.Sequential([tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "                                   tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "                                   tf.keras.layers.Dense(units=1)])\n",
    "long_dense = tf.keras.Sequential([tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "                                   tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "                                   tf.keras.layers.Dense(units=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', single_step_window.example[0].shape)\n",
    "print('Output shape:', long_dense(single_step_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54133421",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses = compile_and_fit(short_dense, short_data_train_by_zc_tf, short_data_test_by_zc_tf, MAX_EPOCHS)\n",
    "plt.plot(np.arange(1, len(losses) + 1), losses, label='train')\n",
    "plt.plot(np.arange(1, len(val_losses) + 1), val_losses, label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses = compile_and_fit(long_dense, long_data_train_by_zc_tf, long_data_test_by_zc_tf, MAX_EPOCHS)\n",
    "plt.plot(np.arange(1, len(losses) + 1), losses, label='train')\n",
    "plt.plot(np.arange(1, len(val_losses) + 1), val_losses, label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f293b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', long_dense(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97376e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_plot_model(long_dense, wide_long_data_train_by_zc_tf, wide_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9324c",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "long_lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f615345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', long_lstm_model(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses = compile_and_fit(short_lstm_model, wide_short_data_train_by_zc_tf, wide_short_data_test_by_zc_tf, MAX_EPOCHS)\n",
    "plt.plot(np.arange(1, len(losses) + 1), losses, label='train')\n",
    "plt.plot(np.arange(1, len(val_losses) + 1), val_losses, label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses = compile_and_fit(long_lstm_model, wide_long_data_train_by_zc_tf, wide_long_data_test_by_zc_tf, MAX_EPOCHS)\n",
    "plt.plot(np.arange(1, len(losses) + 1), losses, label='train')\n",
    "plt.plot(np.arange(1, len(val_losses) + 1), val_losses, label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33098793",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', long_lstm_model(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27da1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_plot_model(long_lstm_model, wide_long_data_train_by_zc_tf, wide_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6c0cf0",
   "metadata": {},
   "source": [
    "# MultiStep Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_STEPS = 3\n",
    "multi_window = WindowGenerator(input_width=OUT_STEPS,\n",
    "                               label_width=OUT_STEPS,\n",
    "                               shift=OUT_STEPS)\n",
    "\n",
    "multi_window.plot()\n",
    "multi_wide_short_data_train_by_zc_tf, multi_wide_short_data_test_by_zc_tf = split_by_zip_code(short_ohe_data_train, short_ohe_data_test, multi_window, ignore_test=True)\n",
    "multi_wide_long_data_train_by_zc_tf, multi_wide_long_data_test_by_zc_tf = split_by_zip_code(long_ohe_data_train, long_ohe_data_test, multi_window)\n",
    "multi_window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f38374",
   "metadata": {},
   "source": [
    "### Autoregressive LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8092ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = long_ohe_data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75697c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedBack(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdeab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup(self, inputs):\n",
    "    # inputs.shape => (batch, time, features)\n",
    "    # x.shape => (batch, lstm_units)\n",
    "    x, *state = self.lstm_rnn(inputs)\n",
    "\n",
    "    # predictions.shape => (batch, features)\n",
    "    prediction = self.dense(x)\n",
    "    return prediction, state\n",
    "\n",
    "FeedBack.warmup = warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self, inputs, training=None):\n",
    "    # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "    predictions = []\n",
    "    # Initialize the LSTM state.\n",
    "    prediction, state = self.warmup(inputs)\n",
    "\n",
    "    # Insert the first prediction.\n",
    "    predictions.append(prediction)\n",
    "\n",
    "    # Run the rest of the prediction steps.\n",
    "    for n in range(1, self.out_steps):\n",
    "        # Use the last prediction as input.\n",
    "        x = prediction\n",
    "        # Execute one lstm step.\n",
    "        x, state = self.lstm_cell(x, states=state,\n",
    "                                  training=training)\n",
    "        # Convert the lstm output to a prediction.\n",
    "        prediction = self.dense(x)\n",
    "        # Add the prediction to the output.\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    # predictions.shape => (time, batch, features)\n",
    "    predictions = tf.stack(predictions)\n",
    "    # predictions.shape => (batch, time, features)\n",
    "    predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "    return predictions\n",
    "\n",
    "FeedBack.call = call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c15b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_feedback_model = FeedBack(units=256, out_steps=OUT_STEPS)\n",
    "long_feedback_model = FeedBack(units=256, out_steps=OUT_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb942ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses = compile_and_fit(short_feedback_model, multi_wide_short_data_train_by_zc_tf, multi_wide_short_data_test_by_zc_tf, MAX_EPOCHS)\n",
    "plt.plot(np.arange(1, len(losses) + 1), losses, label='train')\n",
    "plt.plot(np.arange(1, len(val_losses) + 1), val_losses, label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b77405",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, val_losses = compile_and_fit(long_feedback_model, multi_wide_long_data_train_by_zc_tf, multi_wide_long_data_test_by_zc_tf, MAX_EPOCHS)\n",
    "plt.plot(np.arange(1, len(losses) + 1), losses, label='train')\n",
    "plt.plot(np.arange(1, len(val_losses) + 1), val_losses, label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', multi_window.example[0].shape)\n",
    "print('Output shape:', long_feedback_model(multi_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_wide_plot_model(model, wide_data, window, extra_steps):\n",
    "    inputs, labels = next(iter(wide_data['zip_91915.0']))\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_col_index = window.column_indices['est']\n",
    "\n",
    "    plt.ylabel(f'est [normed]')\n",
    "    plt.plot(window.input_indices, inputs[0, :, plot_col_index],\n",
    "             label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "    if window.label_columns:\n",
    "        label_col_index = window.label_columns_indices.get('est', None)\n",
    "    else:\n",
    "        label_col_index = plot_col_index\n",
    "\n",
    "    plt.scatter(window.label_indices, labels[0, :, label_col_index],\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "\n",
    "    model.out_steps += extra_steps\n",
    "    predictions = model(inputs, training=False)\n",
    "    model.out_steps -= extra_steps\n",
    "    new_pred_indicies = np.append(multi_window.label_indices, np.arange(multi_window.label_indices[-1] + 1, multi_window.label_indices[-1] + 1 + extra_steps))\n",
    "    plt.scatter(new_pred_indicies, predictions[0, :, label_col_index],\n",
    "                marker='X', edgecolors='k', label='Predictions',\n",
    "                c='#ff7f0e', s=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_wide_plot_model(long_feedback_model, multi_wide_long_data_train_by_zc_tf, multi_window, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_auto_wide_plot_model(model, wide_data, window, extra_steps):\n",
    "    \n",
    "    total_preds = None\n",
    "    total_inputs = None\n",
    "    plot_col_index = window.column_indices['est']\n",
    "    if window.label_columns:\n",
    "        label_col_index = window.label_columns_indices.get('est', None)\n",
    "    else:\n",
    "        label_col_index = plot_col_index\n",
    "    model.out_steps += extra_steps\n",
    "    \n",
    "    for zc in wide_data.keys():\n",
    "        \n",
    "        inputs, labels = next(iter(wide_data[zc]))\n",
    "        \n",
    "        predictions = model(inputs, training=False)\n",
    "        curr_preds = unstandardize_series(predictions[0, :, label_col_index], long_train_mean['est'], long_train_std['est'])\n",
    "        curr_inputs = unstandardize_series(inputs[0, :, plot_col_index], long_train_mean['est'], long_train_std['est'])\n",
    "        \n",
    "        if total_preds is None:\n",
    "            total_preds = curr_preds\n",
    "        else:\n",
    "            total_preds += curr_preds\n",
    "            \n",
    "        if total_inputs is None:\n",
    "            total_inputs = curr_inputs\n",
    "        else:\n",
    "            total_inputs += curr_inputs\n",
    "            \n",
    "    model.out_steps -= extra_steps\n",
    "    \n",
    "    return total_inputs, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc30a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_regressive_steps = 2200-2017\n",
    "sum_inputs, sum_preds = sum_auto_wide_plot_model(long_feedback_model, multi_wide_long_data_train_by_zc_tf, multi_window, auto_regressive_steps)\n",
    "\n",
    "input_indicies = np.arange(2012, 2012 + sum_inputs.shape[0])\n",
    "preds_indicies = np.arange(input_indicies[0] + 3, input_indicies[-1] + auto_regressive_steps + 4)\n",
    "\n",
    "plt.plot(input_indicies, sum_inputs, marker='o')\n",
    "plt.plot(preds_indicies, sum_preds, marker='X', color='#ff7f0e')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40c07c9",
   "metadata": {},
   "source": [
    "# TF MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996cfebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uni_window = WindowGenerator(input_width=1,\n",
    "                                  label_width=1,\n",
    "                                  shift=1,\n",
    "                                  label_columns=['est'],\n",
    "                                  batch_size=1)\n",
    "test_uni_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uni_short_data_train_by_zc_tf, test_uni_short_data_test_by_zc_tf = split_by_zip_code(tf_short_ohe_data_train, tf_short_ohe_data_test, test_uni_window)\n",
    "test_uni_long_data_train_by_zc_tf, test_uni_long_data_test_by_zc_tf = split_by_zip_code(tf_long_ohe_data_train, tf_long_ohe_data_test, test_uni_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = [('baseline', baseline, baseline), ('linear', short_linear, long_linear), \n",
    "                  ('dense', short_dense, long_dense), ('lstm', short_lstm_model, long_lstm_model), \n",
    "                  ('autoregressive-lstm', short_feedback_model, long_feedback_model)]\n",
    "\n",
    "testing_scenarios = [('short-term', test_uni_short_data_train_by_zc_tf, test_uni_short_data_test_by_zc_tf),\n",
    "                     ('long-term', test_uni_long_data_train_by_zc_tf, test_uni_long_data_test_by_zc_tf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c61763",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_info = []\n",
    "for model_name, short_model, long_model in models_to_test:\n",
    "    model_eval = [model_name]\n",
    "    for scenario_name, train_data, test_data in testing_scenarios:\n",
    "        if scenario_name == 'short-term':\n",
    "            model = short_model\n",
    "        else:\n",
    "            model = long_model\n",
    "        train_rmse = evaluate_on_all_zip(model, train_data)\n",
    "        test_rmse = evaluate_on_all_zip(model, test_data)\n",
    "        model_eval += [train_rmse]\n",
    "        model_eval += [test_rmse]\n",
    "            \n",
    "    eval_info += [model_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_info += [['lr', short_lr_train_rmse, short_lr_test_rmse,\n",
    "                     long_lr_train_rmse, long_lr_test_rmse]]\n",
    "eval_info += [['rf', short_rf_train_rmse, short_rf_test_rmse,\n",
    "                     long_rf_train_rmse, long_rf_test_rmse]]\n",
    "eval_info += [['lasso', short_lasso_train_rmse, short_lasso_test_rmse,\n",
    "                        long_lasso_train_rmse, long_lasso_test_rmse]]\n",
    "eval_info += [['arima', short_arima_train_rmse, short_arima_test_rmse,\n",
    "                        long_arima_train_rmse, long_arima_test_rmse]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f13f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_df = pd.DataFrame(eval_info, columns=['model', \n",
    "                                           'short-term train rmse', 'short-term test rmse',\n",
    "                                           'long-term train rmse', 'long-term test rmse'])\n",
    "evals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782c6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_df[['model', 'short-term test rmse', 'long-term test rmse']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84923f4f",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f09222",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_model_filepath = '../../out/models/short_feedback_model_weights.tf'\n",
    "long_model_filepath = '../../out/models/long_feedback_model_weights.tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short_feedback_model.save_weights(short_model_filepath)\n",
    "# long_feedback_model.save_weights(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a3fd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_short_feedback = FeedBack(units=256, out_steps=OUT_STEPS)\n",
    "loaded_short_feedback.built = True\n",
    "loaded_short_feedback.load_weights(short_model_filepath)\n",
    "\n",
    "loaded_long_feedback = FeedBack(units=256, out_steps=OUT_STEPS)\n",
    "loaded_long_feedback.built = True\n",
    "loaded_long_feedback.load_weights(long_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d70658",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_regressive_steps = 2200-2017\n",
    "sum_inputs, sum_preds = sum_auto_wide_plot_model(loaded_short_feedback, multi_wide_long_data_train_by_zc_tf, multi_window, auto_regressive_steps)\n",
    "\n",
    "input_indicies = np.arange(2012, 2012 + sum_inputs.shape[0])\n",
    "preds_indicies = np.arange(input_indicies[0] + 3, input_indicies[-1] + auto_regressive_steps + 4)\n",
    "\n",
    "plt.plot(input_indicies, sum_inputs, marker='o')\n",
    "plt.plot(preds_indicies, sum_preds, marker='X', color='#ff7f0e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_regressive_steps = 2200-2017\n",
    "sum_inputs, sum_preds = sum_auto_wide_plot_model(loaded_long_feedback, multi_wide_long_data_train_by_zc_tf, multi_window, auto_regressive_steps)\n",
    "\n",
    "input_indicies = np.arange(2012, 2012 + sum_inputs.shape[0])\n",
    "preds_indicies = np.arange(input_indicies[0] + 3, input_indicies[-1] + auto_regressive_steps + 4)\n",
    "\n",
    "plt.plot(input_indicies, sum_inputs, marker='o')\n",
    "plt.plot(preds_indicies, sum_preds, marker='X', color='#ff7f0e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d89521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
