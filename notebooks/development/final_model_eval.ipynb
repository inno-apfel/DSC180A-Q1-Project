{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a42858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca3bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "class ARIMAForecast():\n",
    "    \n",
    "    def __init__(self, data, n_lag_terms ,diff_order ,window_size):\n",
    "        self.data = data\n",
    "        self.models = {}\n",
    "        self.n_lag_terms = n_lag_terms\n",
    "        self.diff_order = diff_order\n",
    "        self.window_size = window_size\n",
    "        \n",
    "    def train(self):\n",
    "        for zip_code in self.data['zip'].unique():\n",
    "            # filter\n",
    "            curr_data = self.data[self.data['zip']==zip_code][['year', 'est']].set_index('year')\n",
    "            start_time = curr_data.index[0]\n",
    "            # train\n",
    "            model = ARIMA(curr_data, order=(self.n_lag_terms ,self.diff_order ,self.window_size))\n",
    "            try:\n",
    "                results = model.fit()\n",
    "                self.models[zip_code] = (results, start_time)\n",
    "            except:\n",
    "                pass\n",
    "#                 print(zip_code)\n",
    "#                 print(curr_data)\n",
    "            \n",
    "    def forecast(self, year):\n",
    "        preds = []\n",
    "        # last year seen in the training set\n",
    "        # used to calculate start range for forecast, to avoid predicting values in training set\n",
    "        data_last_year = self.data['year'].max()\n",
    "        for zip_code, model_info in self.models.items():\n",
    "            model, start_time = model_info\n",
    "            # make predictions\n",
    "            curr_pred = model.predict(data_last_year-start_time+1,year-start_time)\n",
    "            # modify results into a df object\n",
    "            curr_pred = curr_pred.to_frame().assign(zip=np.full(curr_pred.shape[0], zip_code)).reset_index()\n",
    "            curr_pred = curr_pred.rename(columns={'index':'year', 0:'est', 'predicted_mean':'est'})\n",
    "            # address issue where timestamp of some predictions is the number of years after the last year\n",
    "            # in the training data rather than a timestamp object\n",
    "            max_int = curr_pred[curr_pred['year'].apply(lambda x: type(x) == int)]['year'].max()\n",
    "            curr_pred['year'] = curr_pred['year'].apply(lambda x: year-max_int+x if (type(x) == int) else x)\n",
    "            preds += [curr_pred]\n",
    "            \n",
    "        return pd.concat(preds, ignore_index=True).reset_index(drop=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7c792",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../src/data/temp/zbp_totals_with_features.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2dbbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../src/data/temp/lagged_zbp_totals_with_features.csv'\n",
    "lagged_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['year'] <= 2020]\n",
    "lagged_data = lagged_data[lagged_data['year'] <= 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e833d66",
   "metadata": {},
   "source": [
    "# Drop Categorical Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numerical_cols = data.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "data = data.drop(columns=non_numerical_cols)\n",
    "\n",
    "non_numerical_cols = lagged_data.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "lagged_data = lagged_data.drop(columns=non_numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316896d1",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346f10a9",
   "metadata": {},
   "source": [
    "### Short-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e32601",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_year = 2020 - 1\n",
    "\n",
    "short_data_train = data[data['year'] <= end_year]\n",
    "short_data_test = data[data['year'] > end_year]\n",
    "\n",
    "short_lagged_data_train = lagged_data[lagged_data['year'] <= end_year]\n",
    "short_lagged_data_test = lagged_data[lagged_data['year'] > end_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168dcbe",
   "metadata": {},
   "source": [
    "### Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458cb2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_year = 2018 - 1\n",
    "\n",
    "long_data_train = data[data['year'] <= end_year]\n",
    "long_data_test = data[data['year'] > end_year]\n",
    "\n",
    "long_lagged_data_train = lagged_data[lagged_data['year'] <= end_year]\n",
    "long_lagged_data_test = lagged_data[lagged_data['year'] > end_year]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a99ab3e",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a220458",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_lagged_train_mean = short_lagged_data_train.mean()\n",
    "short_lagged_train_mean['zip'] = 0\n",
    "short_lagged_train_std = short_lagged_data_train.std()\n",
    "short_lagged_train_std['zip'] = 1\n",
    "\n",
    "long_lagged_train_mean = long_lagged_data_train.mean()\n",
    "long_lagged_train_mean['zip'] = 0\n",
    "long_lagged_train_std = long_lagged_data_train.std()\n",
    "long_lagged_train_std['zip'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ebca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_lagged_data_train = (short_lagged_data_train - short_lagged_train_mean) / short_lagged_train_std\n",
    "short_lagged_data_test = (short_lagged_data_test - short_lagged_train_mean) / short_lagged_train_std\n",
    "\n",
    "long_lagged_data_train = (long_lagged_data_train - long_lagged_train_mean) / long_lagged_train_std\n",
    "long_lagged_data_test = (long_lagged_data_test - long_lagged_train_mean) / long_lagged_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6ed78",
   "metadata": {},
   "source": [
    "# Forward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540ae71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = data_train.drop(columns=['est'])\n",
    "# y_train = data_train['est']\n",
    "# X_test = data_test.drop(columns=['est'])\n",
    "# y_test = data_test['est']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2152640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffs = SequentialFeatureSelector(LinearRegression(n_jobs=-1), k_features=11, forward=True, n_jobs=-1)\n",
    "# ffs.fit(X_train, y_train)\n",
    "# features = list(ffs.k_feature_names_)\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874119f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl, train_rmse, test_rmse = fit_eval(pl, data_train, data_test, features)\n",
    "# print('train_rmse: ', train_rmse)\n",
    "# print('test_rmse: ', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65857bd",
   "metadata": {},
   "source": [
    "# Corr Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ohe_train = preproc.fit_transform(data_train)\n",
    "# feature_names = preproc.get_feature_names_out()\n",
    "# feature_names = np.char.replace(feature_names.astype('str'), 'onehots__','')\n",
    "# feature_names = np.char.replace(feature_names, 'remainder__','')\n",
    "\n",
    "# data_ohe_train = pd.DataFrame(data_ohe_train, columns=feature_names)\n",
    "\n",
    "# data_ohe_test = preproc.transform(data_test)\n",
    "# data_ohe_test = pd.DataFrame(data_ohe_test, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1fe12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# top_k = -3\n",
    "# corr = data_ohe_train.corr()[['est']].sort_values(by='est', ascending=False)\n",
    "# vmin = corr.min()\n",
    "# vmax = corr.max()\n",
    "# corr_thresh = corr.abs().sort_values('est', ascending=False).iloc[top_k+2]['est']\n",
    "# corr = corr[corr['est'].abs() > corr_thresh]\n",
    "# print(f'top {corr.shape[0]} features:')\n",
    "# corr[2:].style.background_gradient(cmap='coolwarm', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4227a3",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efefec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstandardize_series(ser, mean, std):\n",
    "    return (ser*std)+mean\n",
    "\n",
    "def fit_eval(model, data_train, data_test, included_feats, train_mean, train_std):\n",
    "    X_train = data_train[included_feats]\n",
    "    y_train = data_train['est']\n",
    "    X_test = data_test[included_feats]\n",
    "    y_test = data_test['est']\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_preds = model.predict(X_train)\n",
    "    inverted_y_train = unstandardize_series(y_train, train_mean['est'], train_std['est'])\n",
    "    inverted_y_preds = unstandardize_series(y_preds, train_mean['est'], train_std['est'])\n",
    "    train_rmse = mean_squared_error(inverted_y_train, inverted_y_preds, squared=False)\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    inverted_y_test = unstandardize_series(y_test, train_mean['est'], train_std['est'])\n",
    "    inverted_y_preds = unstandardize_series(y_preds, train_mean['est'], train_std['est'])\n",
    "    test_rmse = mean_squared_error(inverted_y_test, inverted_y_preds, squared=False)\n",
    "    \n",
    "    return model, train_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a97ae",
   "metadata": {},
   "source": [
    "### Lin Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c7608",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer([('onehots', OneHotEncoder(handle_unknown='ignore'), ['zip'])]\n",
    "                             ,remainder = 'passthrough')\n",
    "pl = Pipeline(steps=[('preproc', preproc), ('lr', LinearRegression(n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697199bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl, train_rmse, test_rmse = fit_eval(pl, short_lagged_data_train, short_lagged_data_test, \n",
    "                                     short_lagged_data_train.columns.drop(['est']), \n",
    "                                     short_lagged_train_mean, short_lagged_train_std)\n",
    "print('train_rmse: ', train_rmse)\n",
    "print('test_rmse: ', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl, train_rmse, test_rmse = fit_eval(pl, long_lagged_data_train, long_lagged_data_test, \n",
    "                                     long_lagged_data_train.columns.drop(['est']), \n",
    "                                     long_lagged_train_mean, long_lagged_train_std)\n",
    "print('train_rmse: ', train_rmse)\n",
    "print('test_rmse: ', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b146c20",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer([('onehots', OneHotEncoder(handle_unknown='ignore'), ['zip'])]\n",
    "                             ,remainder = 'passthrough')\n",
    "pl = Pipeline(steps=[('preproc', preproc), ('lr', Lasso(alpha=0.007))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c941fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl, train_rmse, test_rmse = fit_eval(pl, short_lagged_data_train, short_lagged_data_test, \n",
    "                                     short_lagged_data_train.columns.drop(['est']), \n",
    "                                     short_lagged_train_mean, short_lagged_train_std)\n",
    "print('train_rmse: ', train_rmse)\n",
    "print('test_rmse: ', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb206128",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl, train_rmse, test_rmse = fit_eval(pl, long_lagged_data_train, long_lagged_data_test, \n",
    "                                     long_lagged_data_train.columns.drop(['est']), \n",
    "                                     long_lagged_train_mean, long_lagged_train_std)\n",
    "print('train_rmse: ', train_rmse)\n",
    "print('test_rmse: ', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525c73e",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer([('onehots', OneHotEncoder(handle_unknown='ignore'), ['zip'])]\n",
    "                             ,remainder = 'passthrough')\n",
    "pl = Pipeline(steps=[('preproc', preproc), ('lr', RandomForestRegressor(random_state=42, n_estimators=50, max_depth=50, n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892eea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl, train_rmse, test_rmse = fit_eval(pl, short_lagged_data_train, short_lagged_data_test, \n",
    "                                     short_lagged_data_train.columns.drop(['est']), \n",
    "                                     short_lagged_train_mean, short_lagged_train_std)\n",
    "print('train_rmse: ', train_rmse)\n",
    "print('test_rmse: ', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl, train_rmse, test_rmse = fit_eval(pl, long_lagged_data_train, long_lagged_data_test, \n",
    "                                     long_lagged_data_train.columns.drop(['est']), \n",
    "                                     long_lagged_train_mean, long_lagged_train_std)\n",
    "print('train_rmse: ', train_rmse)\n",
    "print('test_rmse: ', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8269814f",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ae8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ARIMAForecast(short_data_train, 1, 1, 1)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    model.train()\n",
    "forecast = model.forecast(short_data_test['year'].max())\n",
    "preds_labels = forecast.merge(short_data_test, on=['zip', 'year'], suffixes=('_pred', '_true'))\n",
    "mean_squared_error(preds_labels['est_true'], preds_labels['est_pred'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2085d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMAForecast(long_data_train, 1, 1, 1)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    model.train()\n",
    "forecast = model.forecast(long_data_test['year'].max())\n",
    "preds_labels = forecast.merge(long_data_test, on=['zip', 'year'], suffixes=('_pred', '_true'))\n",
    "mean_squared_error(preds_labels['est_true'], preds_labels['est_pred'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809e0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
